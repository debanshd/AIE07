{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align = \"center\" draggable=”false” ><img src=\"https://github.com/AI-Maker-Space/LLM-Dev-101/assets/37101144/d1343317-fa2f-41e1-8af1-1dbb18399719\" \n",
    "     width=\"200px\"\n",
    "     height=\"auto\"/>\n",
    "</p>\n",
    "\n",
    "<h1 align=\"center\" id=\"heading\">OpenAI Agents SDK - AIM</h1>\n",
    "\n",
    "In this notebook, we'll go over some of the key features of the OpenAI Agents SDK - as explored through a notebook-ified version of their [Research Bot](https://github.com/openai/openai-agents-python/tree/main/examples/research_bot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### You don't need to run this cell if you're running this notebook locally. \n",
    "\n",
    "#!pip install -qU openai-agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API Key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nest Async:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents\n",
    "\n",
    "As may be expected, the primary thing we'll do in the Agents SDK is construct Agents!\n",
    "\n",
    "Agents are constructed with a few basic properties:\n",
    "\n",
    "- A prompt, which OpenAI is using the language \"instruction\" for, that determines the behaviour or goal of the Agent\n",
    "- A model, the \"brain\" of the Agent\n",
    "\n",
    "They also typically include an additional property: \n",
    "\n",
    "- Tool(s) that equip the Agent with things it can use to get stuff done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Create Planner Agent\n",
    "\n",
    "Let's start by creating our \"Planner Agent\" - which will come up with the initial set of search terms that should answer a query provided by the user. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from agents import Agent\n",
    "\n",
    "PLANNER_PROMPT = (\n",
    "    \"You are a helpful research assistant. Given a query, come up with a set of web searches to perform\" \n",
    "    \"to best answer the query. Output between 5 and 20 terms to query for.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll define the data models that our Planner Agent will use to structure its output. We'll create:\n",
    "\n",
    "1. `WebSearchItem` - A model for individual search items, containing the search query and reasoning\n",
    "2. `WebSearchPlan` - A container model that holds a list of search items\n",
    "\n",
    "These Pydantic models will help ensure our agent returns structured data that we can easily process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebSearchItem(BaseModel):\n",
    "    reason: str\n",
    "    \"Your reasoning for why this search is important to the query.\"\n",
    "\n",
    "    query: str\n",
    "    \"The search term to use for the web search.\"\n",
    "\n",
    "class WebSearchPlan(BaseModel):\n",
    "    searches: list[WebSearchItem]\n",
    "    \"\"\"A list of web searches to perform to best answer the query.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create our Planner Agent using the Agent class from the OpenAI Agents SDK. This agent will use the instructions defined in `PLANNER_PROMPT` and will output structured data in the form of our WebSearchPlan model. We're using the GPT-4o model for this agent to ensure high-quality search term generation.\n",
    "\n",
    "> NOTE: When we provide an `output_type` - the model will return a [structured response](https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner_agent = Agent(\n",
    "    name=\"PlannerAgent\",\n",
    "    instructions=PLANNER_PROMPT,\n",
    "    model=\"gpt-4.1\",\n",
    "    output_type=WebSearchPlan,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ❓Question #1:\n",
    "\n",
    "Why is it important to provide a structured response template? (As in: Why are structured outputs helpful/preferred in Agentic workflows?)\n",
    "\n",
    "##### ✅ Answer:\n",
    "\n",
    "Structured response templates are crucial in agentic workflows for several key reasons:\n",
    "\n",
    "**1. Predictable Data Processing**\n",
    "- Structured outputs ensure that downstream agents and systems can reliably parse and process the data without ambiguity\n",
    "- When agents communicate with each other (like our Planner → Search → Writer flow), structured responses prevent parsing errors and ensure smooth handoffs\n",
    "- Example: Our `WebSearchPlan` model guarantees that the Search Agent receives a list of `WebSearchItem` objects with `reason` and `query` fields\n",
    "\n",
    "**2. Type Safety and Validation**\n",
    "- Pydantic models (like `WebSearchPlan` and `ReportData`) provide automatic validation of outputs\n",
    "- This catches errors early in the workflow rather than having them surface later when processing unstructured text\n",
    "- Ensures data integrity across the entire agent pipeline\n",
    "\n",
    "**3. Consistent API Design**\n",
    "- Structured outputs create a consistent contract between agents, making the system more maintainable\n",
    "- Developers can rely on specific data structures when building integrations\n",
    "- Reduces the need for custom parsing logic for each agent interaction\n",
    "\n",
    "**4. Better Error Handling**\n",
    "- When outputs are structured, it's easier to detect when an agent has failed to provide the expected data\n",
    "- Validation errors can be caught and handled gracefully\n",
    "- Reduces the likelihood of cascading failures in multi-agent systems\n",
    "\n",
    "**5. Enhanced Debugging and Observability**\n",
    "- Structured outputs make it easier to trace data flow through the system\n",
    "- Debugging becomes more systematic when you can inspect specific fields rather than parsing free-form text\n",
    "- The tracing capabilities in the SDK work better with structured data\n",
    "\n",
    "**6. Improved User Experience**\n",
    "- Structured outputs enable better UI rendering (e.g., displaying search results in a table format)\n",
    "- Users get more consistent and predictable responses\n",
    "- Enables features like progress tracking and status updates\n",
    "\n",
    "**7. Scalability and Integration**\n",
    "- Structured outputs make it easier to integrate with external systems and APIs\n",
    "- Database storage and retrieval becomes more efficient\n",
    "- Enables better caching strategies\n",
    "\n",
    "**8. Reduced Hallucination and Ambiguity**\n",
    "- By constraining the output format, structured responses help reduce the likelihood of agents generating irrelevant or hallucinated content\n",
    "- Clear schemas guide the model to focus on the specific information needed\n",
    "\n",
    "In our research bot example, the structured outputs (`WebSearchPlan`, `ReportData`) ensure that each agent in the pipeline receives exactly the data it expects, enabling a smooth and reliable research workflow from planning searches to generating the final report.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Create Search Agent\n",
    "\n",
    "Now we'll create our Search Agent, which will be responsible for executing web searches based on the terms generated by the Planner Agent. This agent will take each search query, perform a web search using the `WebSearchTool`, and then summarize the results in a concise format.\n",
    "\n",
    "> NOTE: We are using the `WebSearchTool`, a hosted tool that can be used as part of an `OpenAIResponsesModel` as outlined in the [documentation](https://openai.github.io/openai-agents-python/tools/). This is based on the tools available through OpenAI's new [Responses API](https://openai.com/index/new-tools-for-building-agents/).\n",
    "\n",
    "The `SEARCH_PROMPT` below instructs the agent to create brief, focused summaries of search results. These summaries are designed to be 2-3 paragraphs, under 300 words, and capture only the essential information without unnecessary details. The goal is to provide the Writer Agent with clear, distilled information that can be efficiently synthesized into the final report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_PROMPT = (\n",
    "    \"You are a research assistant. Given a search term, you search the web for that term and\"\n",
    "    \"produce a concise summary of the results. The summary must 2-3 paragraphs and less than 300\"\n",
    "    \"words. Capture the main points. Write succinctly, no need to have complete sentences or good\"\n",
    "    \"grammar. This will be consumed by someone synthesizing a report, so its vital you capture the\"\n",
    "    \"essence and ignore any fluff. Do not include any additional commentary other than the summary\"\n",
    "    \"itself.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create our Search Agent using the Agent class from the OpenAI Agents SDK. This agent will use the instructions defined in `SEARCH_PROMPT` and will utilize the `WebSearchTool` to perform web searches. We're configuring it with `tool_choice=\"required\"` to ensure it always uses the search tool when processing requests.\n",
    "\n",
    "> NOTE: We can, as demonstrated, indicate how we want our model to use tools. You can read more about that at the bottom of the page [here](https://openai.github.io/openai-agents-python/agents/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import WebSearchTool\n",
    "from agents.model_settings import ModelSettings\n",
    "\n",
    "search_agent = Agent(\n",
    "    name=\"Search agent\",\n",
    "    instructions=SEARCH_PROMPT,\n",
    "    tools=[WebSearchTool()],\n",
    "    model_settings=ModelSettings(tool_choice=\"required\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ❓ Question #2: \n",
    "\n",
    "What other tools are supported in OpenAI's Responses API?\n",
    "\n",
    "##### ✅ Answer:\n",
    "\n",
    "OpenAI's Responses API supports several built-in tools that can be integrated into agentic workflows:\n",
    "\n",
    "**1. WebSearchTool**\n",
    "- **Purpose**: Performs web searches to gather real-time information from the internet\n",
    "- **Use Case**: Research, fact-checking, gathering current information\n",
    "- **Example**: Used in the research bot to search for specific terms and gather information\n",
    "\n",
    "**2. FileSearchTool**\n",
    "- **Purpose**: Searches through files and documents in a specified directory or storage system\n",
    "- **Use Case**: Document analysis, content retrieval, knowledge base searching\n",
    "- **Example**: Searching through a company's internal documents or knowledge base\n",
    "\n",
    "**3. FileReadTool**\n",
    "- **Purpose**: Reads and extracts content from specific files\n",
    "- **Use Case**: Document processing, content analysis, data extraction\n",
    "- **Example**: Reading and analyzing PDFs, text files, or other document formats\n",
    "\n",
    "**4. CodeInterpreterTool**\n",
    "- **Purpose**: Executes Python code in a sandboxed environment\n",
    "- **Use Case**: Data analysis, calculations, code execution, file manipulation\n",
    "- **Example**: Running data analysis scripts, creating visualizations, or processing data\n",
    "\n",
    "**5. RetrievalTool**\n",
    "- **Purpose**: Retrieves information from vector databases or knowledge bases\n",
    "- **Use Case**: Semantic search, document retrieval, knowledge base queries\n",
    "- **Example**: Searching through embeddings or vectorized documents\n",
    "\n",
    "**6. Custom Tools**\n",
    "- **Purpose**: Developers can create custom tools using the SDK's tool framework\n",
    "- **Use Case**: Integration with external APIs, custom business logic, specialized functionality\n",
    "- **Example**: Custom database queries, API integrations, or domain-specific tools\n",
    "\n",
    "**Key Features of These Tools:**\n",
    "\n",
    "- **Hosted Infrastructure**: Many tools (like WebSearchTool) are hosted by OpenAI, reducing setup complexity\n",
    "- **Automatic Integration**: Tools can be easily added to agents using the `tools` parameter\n",
    "- **Type Safety**: Tools work seamlessly with Pydantic models for structured outputs\n",
    "- **Error Handling**: Built-in error handling and retry mechanisms\n",
    "- **Observability**: All tool usage is traced and can be monitored through the SDK's tracing features\n",
    "\n",
    "**Integration Example:**\n",
    "```python\n",
    "from agents import WebSearchTool, FileSearchTool\n",
    "from agents.model_settings import ModelSettings\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"ResearchAgent\",\n",
    "    instructions=\"Research and analyze information\",\n",
    "    tools=[WebSearchTool(), FileSearchTool()],\n",
    "    model_settings=ModelSettings(tool_choice=\"required\"),\n",
    ")\n",
    "```\n",
    "\n",
    "These tools enable agents to interact with external data sources, perform computations, and access real-time information, making them powerful for building sophisticated AI applications that can handle complex, multi-step tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Create Writer Agent\n",
    "\n",
    "Finally, we'll create our Writer Agent, which will synthesize all the research findings into a comprehensive report. This agent takes the original query and the research summaries from the Search Agent, then produces a structured report with follow-up questions.\n",
    "\n",
    "The Writer Agent will:\n",
    "1. Create an outline for the report structure\n",
    "2. Generate a detailed markdown report (5-10 pages)\n",
    "3. Provide follow-up questions for further research\n",
    "\n",
    "We'll define the prompt for this agent in the next cell. This prompt will instruct the Writer Agent on how to synthesize research findings into a comprehensive report with follow-up questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITER_PROMPT = (\n",
    "    \"You are a senior researcher tasked with writing a cohesive report for a research query. \"\n",
    "    \"You will be provided with the original query, and some initial research done by a research \"\n",
    "    \"assistant.\\n\"\n",
    "    \"You should first come up with an outline for the report that describes the structure and \"\n",
    "    \"flow of the report. Then, generate the report and return that as your final output.\\n\"\n",
    "    \"The final output should be in markdown format, and it should be lengthy and detailed. Aim \"\n",
    "    \"for 5-10 pages of content, at least 1000 words.\\n\"\n",
    "    \"For the follow-up questions, provide exactly 5 unique questions that would help extend \"\n",
    "    \"this research. Do not repeat questions.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🏗️ Activity #1: \n",
    "\n",
    "This prompt is quite generic - modify this prompt to produce a report that is more personalized to either your personal preference, or more appropriate for a specific use case (eg. law domain research)\n",
    "\n",
    "##### ✅ Answer:\n",
    "\n",
    "Here are several ways to modify the `WRITER_PROMPT` to make it more personalized or domain-specific:\n",
    "\n",
    "**1. Legal Domain Research:**\n",
    "```python\n",
    "WRITER_PROMPT = (\n",
    "    \"You are a senior legal researcher and attorney tasked with writing a comprehensive legal analysis report. \"\n",
    "    \"You will be provided with the original legal query and research findings from a legal research assistant.\\n\"\n",
    "    \"You should first create a detailed legal analysis outline that includes: case law review, statutory analysis, \"\n",
    "    \"regulatory considerations, and practical implications. Then, generate a comprehensive legal memorandum.\\n\"\n",
    "    \"The final output should be in legal memorandum format with proper citations, and it should be thorough and \"\n",
    "    \"detailed. Aim for 5-10 pages of content, at least 1500 words.\\n\"\n",
    "    \"For the follow-up questions, provide exactly 5 unique legal research questions that would help extend \"\n",
    "    \"this analysis, focusing on jurisdictional variations, recent case law, or regulatory updates.\"\n",
    ")\n",
    "```\n",
    "\n",
    "**2. Medical/Healthcare Research:**\n",
    "```python\n",
    "WRITER_PROMPT = (\n",
    "    \"You are a senior medical researcher and healthcare professional tasked with writing a comprehensive \"\n",
    "    \"medical research report. You will be provided with the original medical query and research findings.\\n\"\n",
    "    \"You should first create a detailed medical analysis outline that includes: clinical evidence review, \"\n",
    "    \"treatment protocols, patient considerations, and evidence-based recommendations. Then, generate a \"\n",
    "    \"comprehensive medical report.\\n\"\n",
    "    \"The final output should be in medical report format with proper medical terminology, citations, and \"\n",
    "    \"evidence grading. Aim for 5-10 pages of content, at least 1200 words.\\n\"\n",
    "    \"For the follow-up questions, provide exactly 5 unique medical research questions that would help extend \"\n",
    "    \"this analysis, focusing on clinical trials, patient outcomes, or emerging treatments.\"\n",
    ")\n",
    "```\n",
    "\n",
    "**3. Business/Financial Analysis:**\n",
    "```python\n",
    "WRITER_PROMPT = (\n",
    "    \"You are a senior business analyst and financial consultant tasked with writing a comprehensive \"\n",
    "    \"business analysis report. You will be provided with the original business query and market research.\\n\"\n",
    "    \"You should first create a detailed business analysis outline that includes: market analysis, \"\n",
    "    \"financial implications, competitive landscape, and strategic recommendations. Then, generate a \"\n",
    "    \"comprehensive business report.\\n\"\n",
    "    \"The final output should be in business report format with executive summary, key findings, \"\n",
    "    \"and actionable recommendations. Aim for 5-10 pages of content, at least 1500 words.\\n\"\n",
    "    \"For the follow-up questions, provide exactly 5 unique business research questions that would help extend \"\n",
    "    \"this analysis, focusing on market trends, competitive intelligence, or financial projections.\"\n",
    ")\n",
    "```\n",
    "\n",
    "**4. Academic Research:**\n",
    "```python\n",
    "WRITER_PROMPT = (\n",
    "    \"You are a senior academic researcher and professor tasked with writing a comprehensive academic \"\n",
    "    \"research report. You will be provided with the original research query and literature review findings.\\n\"\n",
    "    \"You should first create a detailed academic analysis outline that includes: literature review, \"\n",
    "    \"methodology discussion, theoretical framework, and research implications. Then, generate a \"\n",
    "    \"comprehensive academic report.\\n\"\n",
    "    \"The final output should be in academic paper format with proper citations, methodology section, \"\n",
    "    \"and discussion of findings. Aim for 5-10 pages of content, at least 2000 words.\\n\"\n",
    "    \"For the follow-up questions, provide exactly 5 unique academic research questions that would help extend \"\n",
    "    \"this research, focusing on gaps in literature, methodological improvements, or theoretical applications.\"\n",
    ")\n",
    "```\n",
    "\n",
    "**5. Technical/Engineering Research:**\n",
    "```python\n",
    "WRITER_PROMPT = (\n",
    "    \"You are a senior technical researcher and engineer tasked with writing a comprehensive technical \"\n",
    "    \"analysis report. You will be provided with the original technical query and research findings.\\n\"\n",
    "    \"You should first create a detailed technical analysis outline that includes: technical specifications, \"\n",
    "    \"implementation considerations, performance analysis, and technical recommendations. Then, generate a \"\n",
    "    \"comprehensive technical report.\\n\"\n",
    "    \"The final output should be in technical report format with diagrams, specifications, and technical \"\n",
    "    \"details. Aim for 5-10 pages of content, at least 1500 words.\\n\"\n",
    "    \"For the follow-up questions, provide exactly 5 unique technical research questions that would help extend \"\n",
    "    \"this analysis, focusing on optimization, scalability, or emerging technologies.\"\n",
    ")\n",
    "```\n",
    "\n",
    "**6. Personal Preference (Creative/Storytelling):**\n",
    "```python\n",
    "WRITER_PROMPT = (\n",
    "    \"You are a creative storyteller and narrative researcher tasked with writing an engaging and \"\n",
    "    \"compelling narrative report. You will be provided with the original query and research findings.\\n\"\n",
    "    \"You should first create a detailed narrative outline that includes: story structure, character \"\n",
    "    \"development, thematic elements, and engaging plot points. Then, generate a compelling narrative report.\\n\"\n",
    "    \"The final output should be in storytelling format with vivid descriptions, engaging prose, and \"\n",
    "    \"narrative flow. Aim for 5-10 pages of content, at least 1500 words.\\n\"\n",
    "    \"For the follow-up questions, provide exactly 5 unique creative research questions that would help extend \"\n",
    "    \"this narrative, focusing on character development, plot twists, or thematic exploration.\"\n",
    ")\n",
    "```\n",
    "\n",
    "**Key Modifications Made:**\n",
    "- **Domain-specific terminology and frameworks**\n",
    "- **Specialized outline structures**\n",
    "- **Appropriate citation and formatting requirements**\n",
    "- **Domain-relevant follow-up questions**\n",
    "- **Specific content length and depth requirements**\n",
    "- **Professional context and audience considerations**\n",
    "\n",
    "These modifications make the prompt more targeted and ensure the generated reports are appropriate for the specific domain or use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create our Writer Agent using the Agent class from the OpenAI Agents SDK. This agent will synthesize all the research findings into a comprehensive report. We're configuring it with the `ReportData` output type to structure the response with a short summary, markdown report, and follow-up questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportData(BaseModel):\n",
    "    short_summary: str\n",
    "    \"\"\"A short 2-3 sentence summary of the findings.\"\"\"\n",
    "\n",
    "    markdown_report: str\n",
    "    \"\"\"The final report\"\"\"\n",
    "\n",
    "    follow_up_questions: list[str]\n",
    "    \"\"\"Suggested topics to research further\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll define our Writer Agent using the Agent class from the OpenAI Agents SDK. This agent will take the original query and research summaries, then synthesize them into a comprehensive report with follow-up questions. We've defined a custom output type called `ReportData` that structures the response with a short summary, markdown report, and follow-up questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_agent = Agent(\n",
    "    name=\"WriterAgent\",\n",
    "    instructions=WRITER_PROMPT,\n",
    "    model=\"o3-mini\",\n",
    "    output_type=ReportData,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ❓ Question #3: \n",
    "\n",
    "Why are we electing to use a reasoning model for writing our report?\n",
    "\n",
    "##### ✅ Answer:\n",
    "\n",
    "We're electing to use a reasoning model (like GPT-4o or o3-mini) for writing our report for several important reasons:\n",
    "\n",
    "**1. Complex Synthesis and Analysis**\n",
    "- **Multi-step reasoning**: The writer agent needs to synthesize information from multiple search results, identify patterns, and create coherent narratives\n",
    "- **Critical thinking**: Reasoning models can evaluate the quality and relevance of different sources, prioritize information, and make informed judgments about what to include\n",
    "- **Logical flow**: These models can create well-structured arguments and ensure logical progression from introduction to conclusion\n",
    "\n",
    "**2. Content Quality and Depth**\n",
    "- **Comprehensive analysis**: Reasoning models can go beyond surface-level summarization to provide deeper insights and analysis\n",
    "- **Contextual understanding**: They can understand the relationships between different pieces of information and how they connect to the original query\n",
    "- **Nuanced interpretation**: These models can handle complex topics that require careful consideration of multiple perspectives\n",
    "\n",
    "**3. Structured Output Generation**\n",
    "- **Outline creation**: Reasoning models can first create a logical outline before writing the full report\n",
    "- **Consistent formatting**: They can maintain consistent structure and formatting throughout a lengthy document\n",
    "- **Coherent narrative**: These models can weave together disparate information into a cohesive, readable narrative\n",
    "\n",
    "**4. Quality Control and Validation**\n",
    "- **Fact-checking**: Reasoning models can cross-reference information from multiple sources to identify inconsistencies\n",
    "- **Completeness**: They can ensure all aspects of the query are addressed and identify gaps in the research\n",
    "- **Accuracy**: These models can evaluate the reliability of sources and prioritize high-quality information\n",
    "\n",
    "**5. Adaptive Writing Style**\n",
    "- **Audience consideration**: Reasoning models can adapt the writing style and technical level based on the content and intended audience\n",
    "- **Tone consistency**: They can maintain appropriate tone throughout the document\n",
    "- **Professional standards**: These models can produce reports that meet professional or academic standards\n",
    "\n",
    "**6. Follow-up Question Generation**\n",
    "- **Strategic thinking**: Reasoning models can identify areas where further research would be valuable\n",
    "- **Gap analysis**: They can recognize what information is missing or could be explored further\n",
    "- **Research direction**: These models can suggest specific, actionable research questions that would enhance the analysis\n",
    "\n",
    "**7. Error Detection and Correction**\n",
    "- **Logical inconsistencies**: Reasoning models can identify and resolve contradictions in the source material\n",
    "- **Flow issues**: They can detect and fix problems with document structure or narrative flow\n",
    "- **Completeness checks**: These models can ensure all required sections are present and properly developed\n",
    "\n",
    "**8. Scalability and Consistency**\n",
    "- **Handling complexity**: Reasoning models can manage the complexity of synthesizing multiple sources into a coherent report\n",
    "- **Consistent quality**: They can maintain high quality standards even for lengthy documents\n",
    "- **Efficiency**: These models can process large amounts of information quickly while maintaining analytical depth\n",
    "\n",
    "**Example in Our Research Bot:**\n",
    "In our research workflow, the writer agent receives multiple search summaries and needs to:\n",
    "- Identify the most relevant and reliable information\n",
    "- Create a logical structure that flows from introduction to conclusion\n",
    "- Synthesize findings into actionable insights\n",
    "- Generate meaningful follow-up questions for further research\n",
    "\n",
    "A reasoning model is essential for this task because it can perform the complex cognitive work of analysis, synthesis, and evaluation that goes beyond simple information retrieval or summarization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Create Utility Classes \n",
    "\n",
    "We'll define utility classes to help with displaying progress and managing the research workflow. The Printer class below will provide real-time updates on the research process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Printer class provides real-time progress updates during the research process. It uses Rich's Live display to show dynamic content with spinners for in-progress items and checkmarks for completed tasks. The class maintains a dictionary of items with their completion status and can selectively hide checkmarks for specific items. This creates a clean, interactive console experience that keeps the user informed about the current state of the research workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from rich.console import Console, Group\n",
    "from rich.live import Live\n",
    "from rich.spinner import Spinner\n",
    "\n",
    "class Printer:\n",
    "    def __init__(self, console: Console):\n",
    "        self.live = Live(console=console)\n",
    "        self.items: dict[str, tuple[str, bool]] = {}\n",
    "        self.hide_done_ids: set[str] = set()\n",
    "        self.live.start()\n",
    "\n",
    "    def end(self) -> None:\n",
    "        self.live.stop()\n",
    "\n",
    "    def hide_done_checkmark(self, item_id: str) -> None:\n",
    "        self.hide_done_ids.add(item_id)\n",
    "\n",
    "    def update_item(\n",
    "        self, item_id: str, content: str, is_done: bool = False, hide_checkmark: bool = False\n",
    "    ) -> None:\n",
    "        self.items[item_id] = (content, is_done)\n",
    "        if hide_checkmark:\n",
    "            self.hide_done_ids.add(item_id)\n",
    "        self.flush()\n",
    "\n",
    "    def mark_item_done(self, item_id: str) -> None:\n",
    "        self.items[item_id] = (self.items[item_id][0], True)\n",
    "        self.flush()\n",
    "\n",
    "    def flush(self) -> None:\n",
    "        renderables: list[Any] = []\n",
    "        for item_id, (content, is_done) in self.items.items():\n",
    "            if is_done:\n",
    "                prefix = \"✅ \" if item_id not in self.hide_done_ids else \"\"\n",
    "                renderables.append(prefix + content)\n",
    "            else:\n",
    "                renderables.append(Spinner(\"dots\", text=content))\n",
    "        self.live.update(Group(*renderables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a ResearchManager class that will orchestrate the research process. This class will:\n",
    "1. Plan searches based on the query\n",
    "2. Perform those searches to gather information\n",
    "3. Write a comprehensive report based on the gathered information\n",
    "4. Display progress using our Printer class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "from agents import Runner, custom_span, gen_trace_id, trace\n",
    "\n",
    "class ResearchManager:\n",
    "    def __init__(self):\n",
    "        self.console = Console()\n",
    "        self.printer = Printer(self.console)\n",
    "\n",
    "    async def run(self, query: str) -> None:\n",
    "        trace_id = gen_trace_id()\n",
    "        with trace(\"Research trace\", trace_id=trace_id):\n",
    "            self.printer.update_item(\n",
    "                \"trace_id\",\n",
    "                f\"View trace: https://platform.openai.com/traces/trace?trace_id={trace_id}\",\n",
    "                is_done=True,\n",
    "                hide_checkmark=True,\n",
    "            )\n",
    "\n",
    "            self.printer.update_item(\n",
    "                \"starting\",\n",
    "                \"Starting research...\",\n",
    "                is_done=True,\n",
    "                hide_checkmark=True,\n",
    "            )\n",
    "            search_plan = await self._plan_searches(query)\n",
    "            search_results = await self._perform_searches(search_plan)\n",
    "            report = await self._write_report(query, search_results)\n",
    "\n",
    "            final_report = f\"Report summary\\n\\n{report.short_summary}\"\n",
    "            self.printer.update_item(\"final_report\", final_report, is_done=True)\n",
    "\n",
    "            self.printer.end()\n",
    "\n",
    "        print(\"\\n\\n=====REPORT=====\\n\\n\")\n",
    "        print(f\"Report: {report.markdown_report}\")\n",
    "        print(\"\\n\\n=====FOLLOW UP QUESTIONS=====\\n\\n\")\n",
    "        unique_questions = []\n",
    "        seen = set()\n",
    "        \n",
    "        for question in report.follow_up_questions:\n",
    "            if question not in seen:\n",
    "                unique_questions.append(question)\n",
    "                seen.add(question)\n",
    "        \n",
    "        for i, question in enumerate(unique_questions, 1):\n",
    "            print(f\"{i}. {question}\")\n",
    "\n",
    "    async def _plan_searches(self, query: str) -> WebSearchPlan:\n",
    "        self.printer.update_item(\"planning\", \"Planning searches...\")\n",
    "        result = await Runner.run(\n",
    "            planner_agent,\n",
    "            f\"Query: {query}\",\n",
    "        )\n",
    "        self.printer.update_item(\n",
    "            \"planning\",\n",
    "            f\"Will perform {len(result.final_output.searches)} searches\",\n",
    "            is_done=True,\n",
    "        )\n",
    "        return result.final_output_as(WebSearchPlan)\n",
    "\n",
    "    async def _perform_searches(self, search_plan: WebSearchPlan) -> list[str]:\n",
    "        with custom_span(\"Search the web\"):\n",
    "            self.printer.update_item(\"searching\", \"Searching...\")\n",
    "            num_completed = 0\n",
    "            max_concurrent = 5\n",
    "            results = []\n",
    "            \n",
    "            for i in range(0, len(search_plan.searches), max_concurrent):\n",
    "                batch = search_plan.searches[i:i+max_concurrent]\n",
    "                tasks = [asyncio.create_task(self._search(item)) for item in batch]\n",
    "                \n",
    "                for task in asyncio.as_completed(tasks):\n",
    "                    try:\n",
    "                        result = await task\n",
    "                        if result is not None:\n",
    "                            results.append(result)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Search error: {e}\")\n",
    "                        \n",
    "                    num_completed += 1\n",
    "                    self.printer.update_item(\n",
    "                        \"searching\", f\"Searching... {num_completed}/{len(search_plan.searches)} completed\"\n",
    "                    )\n",
    "            \n",
    "            self.printer.mark_item_done(\"searching\")\n",
    "            return results\n",
    "\n",
    "    async def _search(self, item: WebSearchItem) -> str | None:\n",
    "        input = f\"Search term: {item.query}\\nReason for searching: {item.reason}\"\n",
    "        try:\n",
    "            result = await Runner.run(\n",
    "                search_agent,\n",
    "                input,\n",
    "            )\n",
    "            return str(result.final_output)\n",
    "        except Exception as e:\n",
    "            print(f\"Error searching for '{item.query}': {e}\")\n",
    "            return None\n",
    "\n",
    "    async def _write_report(self, query: str, search_results: list[str]) -> ReportData:\n",
    "        self.printer.update_item(\"writing\", \"Thinking about report...\")\n",
    "        input = f\"Original query: {query}\\nSummarized search results: {search_results}\"\n",
    "        \n",
    "        result = Runner.run_streamed(\n",
    "            writer_agent,\n",
    "            input,\n",
    "        )\n",
    "        \n",
    "        update_messages = [\n",
    "            \"Thinking about report...\",\n",
    "            \"Planning report structure...\",\n",
    "            \"Writing outline...\",\n",
    "            \"Creating sections...\",\n",
    "            \"Cleaning up formatting...\",\n",
    "            \"Finalizing report...\",\n",
    "            \"Finishing report...\",\n",
    "        ]\n",
    "\n",
    "        last_update = time.time()\n",
    "        next_message = 0\n",
    "        \n",
    "        async for event in result.stream_events():\n",
    "            if time.time() - last_update > 5 and next_message < len(update_messages):\n",
    "                self.printer.update_item(\"writing\", update_messages[next_message])\n",
    "                next_message += 1\n",
    "                last_update = time.time()\n",
    "\n",
    "        self.printer.mark_item_done(\"writing\")\n",
    "        return result.final_output_as(ReportData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🏗️ Activity #2:\n",
    "\n",
    "Convert the above flow into a flowchart style image (software of your choosing, but if you're not sure which to use try [Excallidraw](https://excalidraw.com/)) that outlines how the different Agents interact with each other. \n",
    "\n",
    "> HINT: Cursor's AI (CMD+L or CTRL+L on Windows) would be a helpful way to get a basic diagram that you can add more detail to!\n",
    "\n",
    "##### ✅ Answer:\n",
    "\n",
    "![flowchart](./flowchart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Running Our Agent\n",
    "\n",
    "Now let's run our agent! The main function below will prompt the user for a research topic, then pass that query to our ResearchManager to handle the entire research process. The ResearchManager will: \n",
    "\n",
    "1. Break down the query into search items\n",
    "2. Search for information on each item\n",
    "3. Write a comprehensive report based on the search results\n",
    "\n",
    "Let's see it in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main() -> None:\n",
    "    query = input(\"What would you like to research? \")\n",
    "    await ResearchManager().run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07540ddf6b1e4592973ec1c7ebcbbdce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=====REPORT=====\n",
      "\n",
      "\n",
      "Report: # Report on Handling No-Input and Inferring User Intent in Conversational and Virtual Assistant Environments\n",
      "\n",
      "## Table of Contents\n",
      "\n",
      "1. [Introduction](#introduction)\n",
      "2. [Strategies for Managing No-Input in Conversational Interfaces](#strategies-for-managing-no-input-in-conversational-interfaces)\n",
      "   1. [Conversational Repairs and Rapid Reprompts](#conversational-repairs-and-rapid-reprompts)\n",
      "   2. [Implementing Hints and Cues](#implementing-hints-and-cues)\n",
      "   3. [Designing Fallback Mechanisms](#designing-fallback-mechanisms)\n",
      "3. [Handling Empty User Inputs in Virtual Assistant Platforms](#handling-empty-user-inputs-in-virtual-assistant-platforms)\n",
      "   1. [Case Study: ServiceNow, Nuance, and Voiceflow](#case-study-servicenow-nuance-and-voiceflow)\n",
      "   2. [Technical Configurations for NLP and Dialogflow](#technical-configurations-for-nlp-and-dialogflow)\n",
      "4. [Evaluating the Role of Research Assistants](#evaluating-the-role-of-research-assistants)\n",
      "   1. [Core Responsibilities and Skill Sets](#core-responsibilities-and-skill-sets)\n",
      "   2. [Interview and Evaluation Strategies](#interview-and-evaluation-strategies)\n",
      "5. [Key Considerations When Hiring Virtual Assistants](#key-considerations-when-hiring-virtual-assistants)\n",
      "6. [Inferring User Intent Without Explicit Queries](#inferring-user-intent-without-explicit-queries)\n",
      "   1. [Analytical Methods](#analytical-methods)\n",
      "   2. [AI and Machine Learning Techniques](#ai-and-machine-learning-techniques)\n",
      "   3. [Collaborative and Social Media Approaches](#collaborative-and-social-media-approaches)\n",
      "7. [Conclusion and Future Directions](#conclusion-and-future-directions)\n",
      "\n",
      "---\n",
      "\n",
      "## Introduction\n",
      "\n",
      "Digital interactions in today's world are increasingly mediated through conversational interfaces and virtual assistants. In scenarios where users provide limited or no input, it is crucial to implement strategies that not only salvage the conversation but also steer it toward productive outcomes. This report examines several institutional practices and technical methods used by leading platforms to maintain engagement when faced with empty or ambiguous user input. By comparing diverse methodologies—from conversational repair strategies to leveraging artificial intelligence (AI) for intent analysis—we provide a comprehensive outlook that aids developers, researchers, and user experience (UX) designers alike.\n",
      "\n",
      "The dynamics of user interaction are especially nuanced when interfacing with software-driven assistants. Whether it is a virtual agent like ServiceNow’s Virtual Agent or context-specific functionalities within platforms like Voiceflow and Dialogflow, developers are constantly refining their systems to better handle silence or unclear inputs. Moreover, the necessity of adapting these strategies extends into broader aspects such as handling research assistant interview questions and clarifying queries in hiring virtual assistants. Through a combination of case studies, technical recommendations, and research insights, this report navigates the multifaceted domain of user input absence and the art of inferring user intent.\n",
      "\n",
      "## Strategies for Managing No-Input in Conversational Interfaces\n",
      "\n",
      "Conversational interfaces have become an integral part of how individuals interact with digital technology. A recurring challenge in these systems is managing instances when users do not provide any input. The following strategies are pivotal in ensuring that the conversation is not stalled:\n",
      "\n",
      "### Conversational Repairs and Rapid Reprompts\n",
      "\n",
      "When users provide an empty response, the system must quickly recognize this gap and deploy repair strategies. Conversational repairs involve dynamic prompting that either clarifies the previous input or nudges the conversation forward. Rapid reprompts—short, immediate follow-up questions such as \"Sorry, what was that?\"—serve to gently draw the user back into the conversation.\n",
      "\n",
      "In a practical context, these techniques ensure that users do not feel abandoned by the system, thereby enhancing overall engagement and reducing the anxiety that may come from unclear or ambiguous interaction outcomes.\n",
      "\n",
      "### Implementing Hints and Cues\n",
      "\n",
      "Providing subtle hints and cues in the interface is essential. For instance, prompting messages such as \"… or just tell me to exit this conversation if you don’t want to go on,\" not only guide users about their next steps but also reduce the cognitive load during uncertain interactions.\n",
      "\n",
      "This approach makes it clear what types of responses the interface expects, thus lowering the barrier for participation especially among those less familiar with digital dialogues.\n",
      "\n",
      "### Designing Fallback Mechanisms\n",
      "\n",
      "No conversational system is perfect. When faced with ambiguous or off-topic responses, fallback mechanisms are crucial. Instead of abruptly ending the conversation, an effective system will offer multiple pathways to regain focus. This can include clarifying questions, alternative suggestions, or redirection to another topic area that aligns with the user’s initial intent.\n",
      "\n",
      "These fallback mechanisms add a layer of flexibility to the interaction that is essential for maintaining a user-friendly experience, achieving smooth transitions even during disruptive exchanges.\n",
      "\n",
      "## Handling Empty User Inputs in Virtual Assistant Platforms\n",
      "\n",
      "Multiple platforms have encountered challenges with empty user inputs, and various strategies have been employed to tackle them.\n",
      "\n",
      "### Case Study: ServiceNow, Nuance, and Voiceflow\n",
      "\n",
      "**ServiceNow's Virtual Agent:** Developers have faced issues such as blank prompt bubbles during loopbacks. A workaround has been to configure the User Input node to reference an ’Input Variable’ from the Data Pill Picker. This adjustment enables a seamless continuation of the dialogue even when users type without receiving additional unnecessary prompts.\n",
      "\n",
      "**Nuance Mix:** In the Nuance Mix environment, the handling of empty inputs involves automated messages during moments of latency or inactivity. Such latency messages maintain engagement by informing the user that data is being retrieved, or that a response is forthcoming, preventing abrupt breaks in user attention.\n",
      "\n",
      "**Voiceflow's 'No Reply' Feature:** Voiceflow offers a practical solution by implementing a timeout feature under the User Input configuration. After the set period of inactivity, the system automatically issues a follow-up prompt, ensuring the conversational flow remains uninterrupted.\n",
      "\n",
      "### Technical Configurations for NLP and Dialogflow\n",
      "\n",
      "On the technical side, platforms like Dialogflow require precise configurations in the webhook response. Developers must include both \"speech\" and \"displayText\" parameters, otherwise risking an error message such as \"Empty speech response\". This underscores the need for rigorous testing and ongoing refinement in natural language understanding (NLU) modules.\n",
      "\n",
      "The application of these technical guidelines is crucial for creating adaptive virtual environments that are responsive, resilient, and ever-improving. They allow systems to be more intuitive in handling unexpected interactions, ultimately enhancing the reliability of digital assistant interfaces.\n",
      "\n",
      "## Evaluating the Role of Research Assistants\n",
      "\n",
      "Beyond the realm of virtual assistants, there exists another segment of interactions where understanding user input is paramount: interviews with research assistants. \n",
      "\n",
      "### Core Responsibilities and Skill Sets\n",
      "\n",
      "Research assistants are central to many institutional and academic projects. Their responsibilities include conducting literature reviews, managing data, designing research studies, and preparing comprehensive reports. Beyond these tasks, they are often evaluated on their problem-solving abilities and technical skills related to data analysis and utilization of qualitative and quantitative research methodologies.\n",
      "\n",
      "### Interview and Evaluation Strategies\n",
      "\n",
      "In a typical interview, research assistants might be queried on how they handle ambiguous data or unexpected results. Interviewers investigate capabilities such as attention to detail, ethical handling of data, and the management of multiple deadlines. Moreover, experience with research project management tools and skills in both academic writing and oral communication are often focal points.\n",
      "\n",
      "Competency in using advanced analytics tools and coding in relevant languages (such as Python or R) is increasingly in demand. This robust set of requirements demonstrates the broad spectrum of expectations that research assistants must meet in today’s data-driven environment.\n",
      "\n",
      "## Key Considerations When Hiring Virtual Assistants\n",
      "\n",
      "For both businesses and individual clients, hiring a virtual assistant (VA) involves numerous considerations. The process is significantly enhanced by understanding common queries and concerns:\n",
      "\n",
      "- **Task Capabilities:** VAs are expected to handle a variety of administrative tasks ranging from scheduling and email management to customer service and social media management.\n",
      "- **Communication Methods:** Establishing clear lines of communication is essential. Whether through email, instant messaging apps, or video conferencing, ensuring a smooth interaction channel is paramount.\n",
      "- **Working Hours and Flexibility:** Availability across different time zones, along with part-time or full-time engagement options, is a significant factor for many clients.\n",
      "- **Confidentiality Protocols:** Given the sensitive nature of the data handled by VAs, strict confidentiality agreements and secure communication methods are protocols that must be verified.\n",
      "- **Cost Considerations:** Understanding the cost structures—which can vary widely based on expertise and geographic location—is critical. VAs typically charge hourly rates that reflect their skill and experience.\n",
      "\n",
      "By addressing these focal areas, clients can conduct thorough vetting processes that result in the selection of a VA who best aligns with their specific needs and expectations.\n",
      "\n",
      "## Inferring User Intent Without Explicit Queries\n",
      "\n",
      "When a user provides no explicit query, understanding their underlying intent presents a significant challenge. However, several effective strategies have been devised to overcome this gap:\n",
      "\n",
      "### Analytical Methods\n",
      "\n",
      "One proven method includes analyzing user behavior—examining browsing history, duration on pages, and previous searches—to identify common patterns. Google Analytics is a frequently used tool to derive these insights, offering data-driven evidence of user preferences and needs.\n",
      "\n",
      "### AI and Machine Learning Techniques\n",
      "\n",
      "Incorporating AI and Natural Language Processing (NLP) techniques enables systems to detect intent even when the input is ambiguous. Intent detection and entity recognition algorithms can draw inferences from minimal data. Such technological implementations are central to platforms like Immwit and can be further integrated into custom solutions for enhanced performance.\n",
      "\n",
      "### Collaborative and Social Media Approaches\n",
      "\n",
      "Listening to direct user feedback through customer-facing teams and monitoring social media platforms with tools like Hootsuite provides additional layers of insight. These methods help capture trends and sentiments, which in turn inform content creation and allow for more tailored user assistance.\n",
      "\n",
      "Collectively, these techniques help bridge the gap between explicit user queries and their latent needs, ensuring that the service remains proactive and responsive.\n",
      "\n",
      "## Conclusion and Future Directions\n",
      "\n",
      "In summary, the effective management of no-input situations and the accurate inference of user intent are pivotal for both conversational interfaces and virtual assistant platforms. Through various strategies—including conversational repairs, rapid reprompts, technological adjustments, and the use of fallback mechanisms—engagement can be maintained even under challenging conditions.\n",
      "\n",
      "The report also underscores the importance of understanding the roles and evaluation criteria for research assistants and the complexities involved in hiring virtual assistants. By integrating these diverse domains, developers and organizations can enhance user experience, reduce friction, and ultimately ensure that digital interactions remain fluid and effective.\n",
      "\n",
      "Looking ahead, the future of digital interaction lies at the intersection of human-centered design and advanced AI. With ongoing innovations in machine learning and data analytics, systems can become even more adept at deciphering the subtle nuances of user intent, paving the way for more intuitive and seamless interactions.\n",
      "\n",
      "This research invites continued exploration into hybrid strategies that combine technical refinement with behavioral insights. By fostering collaborations between UX designers, data analysts, and research professionals, the path forward is rich with possibilities for enhancing user engagement and operational efficiency.\n",
      "\n",
      "---\n",
      "\n",
      "*End of Report*\n",
      "\n",
      "\n",
      "=====FOLLOW UP QUESTIONS=====\n",
      "\n",
      "\n",
      "1. How can user behavior analytics be further integrated with AI techniques to improve predictive accuracy in intent detection?\n",
      "2. What are some emerging trends in conversational interface design that address silent user responses?\n",
      "3. How do varying cultural contexts impact the design of conversational repairs and fallback mechanisms?\n",
      "4. What metrics can be established to measure the success of reprompt strategies in virtual assistant interactions?\n",
      "5. How might the integration of voice and text-based inputs enhance the management of empty user responses?\n"
     ]
    }
   ],
   "source": [
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Sample Report in Markdown \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Agents SDK: A Comprehensive Report\n",
    "\n",
    "*Published: October 2023*\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "2. [Core Concepts and Key Features](#core-concepts-and-key-features)\n",
    "3. [Architecture and Developer Experience](#architecture-and-developer-experience)\n",
    "4. [Comparative Analysis with Alternative Frameworks](#comparative-analysis-with-alternative-frameworks)\n",
    "5. [Integrations and Real-World Applications](#integrations-and-real-world-applications)\n",
    "6. [Troubleshooting, Observability, and Debugging](#troubleshooting-observability-and-debugging)\n",
    "7. [Community Impact and Future Directions](#community-impact-and-future-directions)\n",
    "8. [Conclusion](#conclusion)\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In March 2025, OpenAI released the Agents SDK, a groundbreaking, open-source framework aimed at simplifying the development of autonomous AI agents capable of performing intricate tasks with minimal human intervention. Designed with a Python-first approach, the SDK offers a minimal set of abstractions, yet provides all the necessary components to build, debug, and optimize multi-agent workflows. The release marked a significant milestone for developers who seek to integrate large language models (LLMs) with advanced task delegation mechanisms, enabling next-generation automation in various industries.\n",
    "\n",
    "The primary goal of the OpenAI Agents SDK is to streamline the creation of agentic applications by offering core primitives such as *agents*, *handoffs*, and *guardrails*. These primitives are essential for orchestrating autonomous AI systems that perform key functions such as web search, file operations, and even actions on a computer. This report delves into the SDK's features, its operational architecture, integration capabilities, and how it compares to other frameworks in the rapidly evolving landscape of AI development tools.\n",
    "\n",
    "## Core Concepts and Key Features\n",
    "\n",
    "### Agents\n",
    "\n",
    "At the heart of the SDK are **agents**—intelligent entities that encapsulate a specific set of instructions and tools. Each agent is built on top of a large language model and can be customized with its own personality, domain expertise, and operational directives. For example, a \"Math Tutor\" agent could be designed to solve math problems by explaining each step clearly.\n",
    "\n",
    "**Key elements of an agent include:**\n",
    "\n",
    "- **Instructions:** Specific guidelines that shape the agent's responses and behavior in the context of its designated role.\n",
    "- **Tools:** Predefined or dynamically integrated tools that the agent can leverage to access external resources (e.g., web search or file search functionalities).\n",
    "\n",
    "### Handoffs\n",
    "\n",
    "A unique feature introduced by the SDK is the concept of **handoffs**. Handoffs allow agents to delegate tasks to one another based on expertise and contextual needs. This orchestration paves the way for sophisticated workflows where multiple agents work in tandem, each contributing its specialized capabilities to complete a complex task.\n",
    "\n",
    "### Guardrails\n",
    "\n",
    "Safety and reliability remain a cornerstone in AI development, and the SDK introduces **guardrails** as a means of controlling input and output validation. Guardrails help ensure that agents operate within defined safety parameters, preventing unintended actions and mitigating risks associated with autonomous decision-making.\n",
    "\n",
    "### Built-in Debugging and Observability\n",
    "\n",
    "The development process is further enhanced by built-in **tracing and visualization tools**. These tools offer real-time insights into agent interactions, tool invocations, and decision-making pathways, thereby making debugging and optimization more accessible and systematic. The tracing functionality is a vital feature for developers looking to fine-tune agent performance in production environments.\n",
    "\n",
    "## Architecture and Developer Experience\n",
    "\n",
    "### Python-First Approach\n",
    "\n",
    "The SDK is inherently Python-based, making it highly accessible to the vast community of Python developers. By leveraging existing language features without introducing excessive abstractions, the SDK provides both simplicity and power. The installation is straightforward:\n",
    "\n",
    "```bash\n",
    "mkdir my_project\n",
    "cd my_project\n",
    "python -m venv .venv\n",
    "source .venv/bin/activate\n",
    "pip install openai-agents\n",
    "```\n",
    "\n",
    "Once installed, developers can create and configure agents with minimal boilerplate code. The emphasis on a minimal learning curve has been a significant point of praise among early adopters.\n",
    "\n",
    "### Developer Tools and Tutorials\n",
    "\n",
    "In addition to comprehensive official documentation available on OpenAI’s GitHub pages, the community has contributed numerous tutorials and code examples. Video tutorials by experts such as Sam Witteveen and James Briggs provide hands-on demonstrations, ranging from simple agent creation to more sophisticated scenarios involving parallel execution and advanced tool integrations.\n",
    "\n",
    "### Use of Python's Ecosystem\n",
    "\n",
    "The integration with Python’s ecosystem means that developers can immediately apply a range of established libraries and frameworks. For instance, utilizing Pydantic for input validation in guardrails or leveraging visualization libraries to display agent workflows are examples of how the SDK embraces the strengths of Python.\n",
    "\n",
    "## Comparative Analysis with Alternative Frameworks\n",
    "\n",
    "While the OpenAI Agents SDK has received acclaim for its simplicity and robust integration with OpenAI’s ecosystem, other frameworks such as LangGraph, CrewAI, and AutoGen have emerged as viable alternatives. Here’s how they compare:\n",
    "\n",
    "- **LangGraph:** Known for its graph-based architecture, LangGraph is ideal for handling complex and cyclical workflows that require sophisticated state management. However, it comes with a steeper learning curve, making it less accessible for projects that require quick prototyping.\n",
    "\n",
    "- **CrewAI:** Emphasizing a role-based multi-agent system, CrewAI excels in scenarios where collaboration among agents is critical. Its design promotes clear segregation of duties among different agents, which can be beneficial in customer service or large-scale business automation.\n",
    "\n",
    "- **AutoGen:** This framework supports flexible conversation patterns and diverse agent interactions, particularly useful in applications where adaptive dialogue is essential. Nevertheless, AutoGen may introduce additional overhead when managing state and coordinating multiple agents.\n",
    "\n",
    "In contrast, the OpenAI Agents SDK strikes an effective balance by offering a lightweight yet powerful toolset geared towards production readiness. Its strengths lie in its minimal abstractions, ease of integration with various tools (like web search and file search), and built-in observability features that are crucial for debugging and tracing agent interactions.\n",
    "\n",
    "## Integrations and Real-World Applications\n",
    "\n",
    "### Diverse Integrations\n",
    "\n",
    "The real power of the OpenAI Agents SDK surfaces when it is integrated with other systems and platforms. Notable integrations include:\n",
    "\n",
    "- **Box Integration:** Enhancing enterprise content management, Box has adopted the SDK to enable secure AI-powered data processing. This integration allows agents to reliably access and interpret proprietary data.\n",
    "\n",
    "- **Coinbase AgentKit:** With financial capabilities in mind, Coinbase introduced AgentKit, leveraging the SDK to incorporate financial operations and risk analysis directly into AI agents.\n",
    "\n",
    "- **Milvus and Ollama:** These integrations allow the SDK to handle high-performance data queries and run agents on local infrastructure respectively, ensuring both speed and privacy.\n",
    "\n",
    "### Real-World Applications\n",
    "\n",
    "The versatility of the SDK lends itself to a multitude of applications:\n",
    "\n",
    "- **Customer Support:** Automated agents can be built to handle customer inquiries, providing faster and more accurate responses while reducing workload on human agents.\n",
    "\n",
    "- **Content Generation:** In marketing and media, agents can generate high-quality articles, detailed reports, and even code reviews with built-in content guidelines.\n",
    "\n",
    "- **Financial Analysis:** Specialized agents capable of real-time data fetching and market analysis can generate actionable insights for investors and analysts.\n",
    "\n",
    "- **Health and Wellness:** Custom agents can handle tasks such as appointment scheduling, patient record management, and even provide personalized fitness and dietary recommendations.\n",
    "\n",
    "- **Educational Tools:** Intelligent tutoring agents can assist students by providing personalized learning experiences and instant feedback on assignments.\n",
    "\n",
    "These applications underscore the SDK’s transformative potential across various industries, driving the trend towards increased automation and efficiency.\n",
    "\n",
    "## Troubleshooting, Observability, and Debugging\n",
    "\n",
    "### Common Issues and Solutions\n",
    "\n",
    "As with any cutting-edge technology, developers working with the OpenAI Agents SDK have encountered challenges:\n",
    "\n",
    "- **API Key Management:** Authentication errors due to missing or invalid API keys are common. The solution involves ensuring that the `OPENAI_API_KEY` environment variable is correctly set or programmatically configured using OpenAI’s helper functions.\n",
    "\n",
    "- **Rate Limitations:** Rate limits, an intrinsic challenge with API-based services, require developers to monitor dashboard usage and implement retry strategies with exponential backoff.\n",
    "\n",
    "- **Response Delays:** Network latency and high server loads can result in unexpected delays. Developers are advised to check network settings, adhere to best practices in setting request timeouts, and monitor OpenAI’s service status.\n",
    "\n",
    "### Built-In Tracing Capabilities\n",
    "\n",
    "The SDK provides robust tracing tools that log agent inputs, outputs, tool interactions, and error messages. This level of observability is crucial for debugging complex workflows and allows developers to visualize the agent’s decision-making process in real time. By configuring a `TracingConfig` object, developers can capture detailed insights and identify performance bottlenecks.\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "- **Prompt Engineering:** Refine prompts to reduce ambiguity and minimize unexpected outputs.\n",
    "- **Layered Validation:** Use guardrails extensively to ensure inputs and outputs are verified at multiple layers.\n",
    "- **Modular Design:** Break complex tasks into smaller, more manageable components using handoffs to delegate tasks appropriately.\n",
    "\n",
    "## Community Impact and Future Directions\n",
    "\n",
    "### Developer and Enterprise Adoption\n",
    "\n",
    "The release of the OpenAI Agents SDK has been met with enthusiasm within the developer community. Its ease of use, combined with comprehensive documentation and community-driven resources (such as tutorials on Class Central and DataCamp), has accelerated its adoption across educational, enterprise, and research sectors.\n",
    "\n",
    "Several leading organizations, including Box and Coinbase, have integrated the SDK into their workflows, demonstrating its capability to drive real-world business solutions. The open-source nature of the SDK, licensed under the MIT License, further encourages widespread industrial collaboration and innovation.\n",
    "\n",
    "### Future Prospects\n",
    "\n",
    "Looking forward, OpenAI plans to extend the SDK’s support beyond Python, potentially embracing other programming languages like JavaScript. Additionally, future updates are anticipated to expand tool integrations, further enhance safety mechanisms, and streamline the development of multi-agent ecosystems. Planned deprecations of older APIs, such as the Assistants API in favor of the more unified Responses API, underline the SDK’s evolving roadmap aimed at future-proofing agentic applications.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The OpenAI Agents SDK represents a significant step forward in the field of AI development. Its lightweight, Python-first framework facilitates the creation of autonomous agents that can handle a wide array of tasks—from simple inquiries to complex multi-agent systems. The SDK’s robust integration capabilities, combined with its focus on safety and observability, make it an ideal choice for both developers and enterprises seeking to build reliable, scalable agentic applications.\n",
    "\n",
    "In summary, the SDK not only lowers the barrier to entry for developing sophisticated AI applications but also sets the stage for further innovations as the ecosystem evolves. It is poised to become a standard toolkit for the next generation of AI-driven technologies, empowering users across sectors to achieve greater efficiency and creativity in task automation.\n",
    "\n",
    "---\n",
    "\n",
    "*For further reading, developers are encouraged to visit the official OpenAI documentation, join the community forums, and explore real-world use cases to deepen their understanding of this transformative tool.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
