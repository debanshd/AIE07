# LangGraph Evol Instruct MVP

A minimal viable product demonstrating LangGraph + Evol Instruct synthetic data generation with a web interface.

## ğŸ¯ Overview

This MVP reproduces RAGAS functionality using LangGraph and implements the Evol Instruct methodology for synthetic data generation. It provides a complete pipeline from document upload to evolved questions, answers, and contexts.

## ğŸ—ï¸ Architecture

```
langgraph-evol-instruct-mvp/
â”œâ”€â”€ backend/           # Python FastAPI server
â”œâ”€â”€ frontend/          # Angular web interface
â””â”€â”€ vercel.json        # Deployment configuration
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.9+
- Node.js 16+
- OpenAI API key

### Backend Setup
```bash
cd backend/
export OPENAI_API_KEY="your-api-key-here"
pip install -e .
uvicorn api_server:app --reload
```

### Frontend Setup
```bash
cd frontend/
npm install
npm start
```

### Access the Application
- Frontend: http://localhost:4200
- Backend API: http://localhost:8000
- API Docs: http://localhost:8000/docs

## ğŸ“‹ Features

### âœ… Implemented
- **Document Upload**: PDF processing with LangChain
- **Synthetic Data Generation**: Custom RAGAS-like functionality
- **Three Evolution Types**: Simple, multi-context, reasoning
- **Complex Validation**: Quality control and metrics
- **Answer Generation**: LLM-based answer creation
- **Context Matching**: Question-context linking
- **Minimalist Web UI**: Clean, responsive interface
- **Vercel Deployment**: Production-ready configuration

### ğŸ”„ Evolution Types
1. **Simple Evolution**: Basic question modifications
2. **Multi-Context Evolution**: Questions requiring multiple document sections
3. **Reasoning Evolution**: Questions requiring logical reasoning

## ğŸ“Š Output Format

The system generates:
- **Evolved Questions** with IDs and evolution types
- **Answers** linked to question IDs
- **Contexts** linked to question IDs with source information
- **Validation Metrics** for quality assessment

## ğŸ› ï¸ Technology Stack

### Backend
- **LangGraph**: Core workflow orchestration
- **LangChain**: Document processing and LLM integration
- **FastAPI**: Web server and API endpoints
- **OpenAI**: LLM for question generation and answers
- **Pydantic**: Data validation and serialization

### Frontend
- **Angular**: Web application framework
- **TypeScript**: Type-safe development
- **CSS**: Minimalist styling
- **HTTP Client**: API communication

### Deployment
- **Vercel**: Serverless deployment platform
- **Python 3.9**: Backend runtime
- **Node.js**: Frontend build process

## ğŸ“ Project Structure

```
langgraph-evol-instruct-mvp/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ langgraph_app.py      # Core LangGraph implementation
â”‚   â”œâ”€â”€ api_server.py         # FastAPI server
â”‚   â”œâ”€â”€ pyproject.toml        # Python dependencies
â”‚   â””â”€â”€ README.md            # Backend documentation
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ app.component.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ app.component.html
â”‚   â”‚   â”‚   â”œâ”€â”€ app.component.css
â”‚   â”‚   â”‚   â”œâ”€â”€ app.service.ts
â”‚   â”‚   â”‚   â””â”€â”€ app.module.ts
â”‚   â”‚   â”œâ”€â”€ styles.css
â”‚   â”‚   â””â”€â”€ main.ts
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ angular.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â””â”€â”€ README.md            # Frontend documentation
â”œâ”€â”€ vercel.json              # Deployment configuration
â””â”€â”€ README.md               # This file
```

## ğŸ”§ Development

### Backend Development
```bash
cd backend/
# Install dependencies
pip install -e .

# Run development server
uvicorn api_server:app --reload

# Test API
curl http://localhost:8000/health
```

### Frontend Development
```bash
cd frontend/
# Install dependencies
npm install

# Start development server
npm start

# Build for production
npm run build
```

## ğŸš€ Deployment

### Vercel Deployment
1. Connect your repository to Vercel
2. Set environment variables:
   - `OPENAI_API_KEY`: Your OpenAI API key
3. Deploy automatically on push to main branch

### Manual Deployment
```bash
# Build frontend
cd frontend/
npm run build

# Deploy to Vercel
vercel --prod
```

## ğŸ“ˆ API Endpoints

### Core Endpoints
- `POST /upload` - Upload PDF documents
- `GET /results/{id}` - Get processing results
- `GET /results` - List all results
- `GET /health` - Health check

### Example Usage
```bash
# Upload documents
curl -X POST "http://localhost:8000/upload" \
  -H "Content-Type: multipart/form-data" \
  -F "files=@document.pdf"

# Get results
curl "http://localhost:8000/results/result_1"
```

## ğŸ¯ Success Criteria

This MVP successfully demonstrates:
- âœ… **Working end-to-end** flow
- âœ… **Document upload** and processing
- âœ… **Multiple question evolution types**
- âœ… **Complex validation** and quality control
- âœ… **Answer generation** functionality
- âœ… **Web interface** accessibility
- âœ… **Vercel deployment** working
- âœ… **Complete documentation** provided

## ğŸ”„ Future Enhancements

1. **Advanced visualizations**
2. **Comprehensive testing**
3. **Performance optimization**
4. **Better error handling**
5. **User authentication**
6. **Advanced configuration options**
7. **Real-time collaboration**

## ğŸ“„ License

This project is for educational and demonstration purposes.

## ğŸ¤ Contributing

This is an MVP implementation. For production use, consider:
- Adding comprehensive error handling
- Implementing proper authentication
- Adding unit and integration tests
- Optimizing performance
- Enhancing security measures 